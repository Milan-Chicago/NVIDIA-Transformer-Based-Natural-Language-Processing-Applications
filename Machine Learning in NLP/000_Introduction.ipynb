{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Transformer-Based Natural Language Processing Applications\n",
    "### Part 1: Machine Learning in NLP\n",
    "\n",
    "In this lab, you will explore the key feature of Transformer and [BERT](https://arxiv.org/abs/1810.04805) (Bidirectional Encoder Representations from Transformers) architectures, such as the concept of *attention*, which was introduced in the [\"Attention is All You Need!\"(Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762) paper. The Transformer architecture is the precursor to large-scale language models such as BERT and [Megatron](https://developer.nvidia.com/blog/language-modeling-using-megatron-a100-gpu/), which provide leaps in accuracy for natural language processing (NLP) tasks and bring high-quality language-based services within the reach of companies across many industries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Transformer Architecture](010_Transformer.ipynb)<br>\n",
    "    - Transformer Architecture\n",
    "    - Attention\n",
    "    - Encoder Features\n",
    "    - Decoder Features\n",
    "1. [BERT](020_BERT.ipynb)<br>\n",
    "    - BERT Architecture\n",
    "    - Tokenizers\n",
    "    - Contextualized Word Embedding\n",
    "    - Visualizing Attention with BERT\n",
    "1. [Pretraining Language Models](030_PretrainingLM.ipynb)\n",
    "    - Data Preparation\n",
    "    - Tokenizer Training\n",
    "    - BERT Pretraining with NeMo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JupyterLab\n",
    "For this hands-on lab, we use [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/) to manage our environment.  The [JupyterLab Interface](https://jupyterlab.readthedocs.io/en/stable/user/interface.html) is a dashboard that provides access to interactive iPython notebooks, as well as the folder structure of our environment and a terminal window into the Ubuntu operating system. The first view you'll see includes a **menu bar** at the top, a **file browser** in the **left sidebar**, and a **main work area** that is initially open to the \"Launcher\" page. \n",
    "\n",
    "<img src=\"images/jl_launcher.png\">\n",
    "\n",
    "The file browser can be navigated just like any other file explorer. A double click on any of the items will open a new tab with its content.\n",
    "\n",
    "The main work area includes tabbed views of open files that can be closed, moved, and edited as needed. \n",
    "\n",
    "The notebooks, including this one, consist of a series of content and code **cells**.  To execute code in a code cell, press `Shift+Enter` or the \"Run\" button in the menu bar above, while a cell is highlighted. Sometimes, a content cell will get switched to editing mode. Pressing `Shift+Enter` will switch it back to a readable form.\n",
    "\n",
    "Try executing the simple print statement in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight this cell and click [Shift+Enter] to execute\n",
    "print('This is just a simple print statement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
